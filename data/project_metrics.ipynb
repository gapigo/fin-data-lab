{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca5359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Retorno observado - ret\n",
    "Volatilidade - vol\n",
    "Max Drawdown - mdd\n",
    "Meses observados - meses\n",
    "Hit Ratio - hit_ratio\n",
    "Sortino Ratio - sortino\n",
    "Expected Shortfall - es\n",
    "Calmar Ratio - calmar\n",
    "Recovery Time - rec_time\n",
    "Sharpe Ratio - sharpe\n",
    "Information Ratio - info_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac426e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baixando CDINI (Série 12) via JSON (Método Blindado)...\n",
      "Erro na API: 406\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_cdi_ferro_e_fogo():\n",
    "    print(\"Baixando CDINI (Série 12) via JSON (Método Blindado)...\")\n",
    "    \n",
    "    # MUDANÇA: Usamos JSON em vez de CSV. O JSON não bloqueia robôs.\n",
    "    url = \"https://api.bcb.gov.br/dados/serie/bcdata.sgs.12/dados?formato=json\"\n",
    "    \n",
    "    try:\n",
    "        # verify=False pula a checagem de segurança do certificado do governo\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, verify=False, timeout=30)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Erro na API: {response.status_code}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # O Pandas lê JSON nativamente\n",
    "        df = pd.DataFrame(response.json())\n",
    "        \n",
    "        # [PERSONALIZAÇÃO] Se houver coluna __id, removemos\n",
    "        if \"__id\" in df.columns:\n",
    "            df = df.drop(columns=[\"__id\"])\n",
    "            \n",
    "        # Tratamento de dados\n",
    "        df.columns = ['data', 'valor']\n",
    "        df['data'] = pd.to_datetime(df['data'], dayfirst=True)\n",
    "        df['valor'] = pd.to_numeric(df['valor'], errors='coerce') # JSON já vem com ponto\n",
    "        \n",
    "        # Cálculo da Cota Acumulada\n",
    "        df = df.dropna(subset=['valor']).sort_values('data')\n",
    "        df['fator'] = 1 + (df['valor'] / 100)\n",
    "        df['valor'] = df['fator'].cumprod()\n",
    "        df['codigo'] = 'CDINI'\n",
    "        \n",
    "        print(f\"  > Sucesso! {len(df)} registros baixados.\")\n",
    "        return df[['codigo', 'valor', 'data']]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  [ERRO CRÍTICO NO CDI]: {e}\")\n",
    "        return pd.DataFrame()\n",
    "get_cdi_ferro_e_fogo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7773203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baixando Mercado (Yahoo Finance)...\n",
      "Baixando CDI (Série 12) em blocos de 10 anos desde 2000...\n",
      "Baixando IPCA...\n",
      "Sucesso! Índices processados: ['IBOV' 'DOLAR_VENDA' 'CDINI' 'IPCADIANI']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import requests\n",
    "from bcb import sgs\n",
    "from datetime import datetime, date\n",
    "from sqlalchemy import text\n",
    "from common.postgresql import PostgresConnector as db\n",
    "\n",
    "def get_robust_cdi(start_year=2000):\n",
    "    print(f\"Baixando CDI (Série 12) em blocos de 10 anos desde {start_year}...\")\n",
    "    current_year = datetime.now().year\n",
    "    all_chunks = []\n",
    "    \n",
    "    # Divide a busca em janelas de 10 anos para evitar o erro do BCB\n",
    "    for year in range(start_year, current_year + 1, 10):\n",
    "        end_year = min(year + 9, current_year)\n",
    "        start_str = f\"{year}-01-01\"\n",
    "        end_str = f\"{end_year}-12-31\"\n",
    "        \n",
    "        try:\n",
    "            # sgs.get já lida com os headers que causavam o erro 406\n",
    "            df_chunk = sgs.get({'valor': 12}, start=start_str, end=end_str)\n",
    "            if not df_chunk.empty:\n",
    "                all_chunks.append(df_chunk)\n",
    "        except Exception as e:\n",
    "            print(f\"  [AVISO] Falha no bloco {year}-{end_year}: {e}\")\n",
    "\n",
    "    if not all_chunks:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.concat(all_chunks)\n",
    "    \n",
    "    # [PERSONALIZAÇÃO] Removendo __id se a biblioteca bcb a incluir futuramente\n",
    "    if \"__id\" in df.columns:\n",
    "        df = df.drop(columns=[\"__id\"])\n",
    "\n",
    "    # Ordenação e Cálculo do CDINI (Cota Acumulada)\n",
    "    df = df.sort_index()\n",
    "    df['valor'] = (1 + df['valor'] / 100).cumprod()\n",
    "    df = df.reset_index().rename(columns={'Date': 'data'})\n",
    "    df['codigo'] = 'CDINI'\n",
    "    \n",
    "    return df[['codigo', 'valor', 'data']]\n",
    "\n",
    "def process_all_indices_v6():\n",
    "    # 1. Mercado (Yahoo)\n",
    "    try:\n",
    "        print(\"Baixando Mercado (Yahoo Finance)...\")\n",
    "        tickers = ['^BVSP', 'BRL=X']\n",
    "        data = yf.download(tickers, start='2000-01-01', progress=False)\n",
    "        \n",
    "        # Tratamento de MultiIndex para versões novas do yfinance\n",
    "        if isinstance(data.columns, pd.MultiIndex):\n",
    "            prices = data.xs('Adj Close', level=0, axis=1) if 'Adj Close' in data.columns.get_level_values(0) else data.xs('Close', level=0, axis=1)\n",
    "        else:\n",
    "            prices = data['Adj Close'] if 'Adj Close' in data.columns else data['Close']\n",
    "            \n",
    "        df_ibov = prices['^BVSP'].dropna().reset_index()\n",
    "        df_ibov.columns = ['data', 'valor']\n",
    "        df_ibov['codigo'] = 'IBOV'\n",
    "        \n",
    "        df_dolar = prices['BRL=X'].dropna().reset_index()\n",
    "        df_dolar.columns = ['data', 'valor']\n",
    "        df_dolar['codigo'] = 'DOLAR_VENDA'\n",
    "        df_m = pd.concat([df_ibov, df_dolar])\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no Yahoo: {e}\")\n",
    "        df_m = pd.DataFrame()\n",
    "\n",
    "    # 2. CDI (Obrigatório) - Método Robusto por Blocos\n",
    "    df_c = get_robust_cdi(2000)\n",
    "    if df_c.empty:\n",
    "        raise Exception(\"O CDINI falhou em todas as tentativas. Processo interrompido.\")\n",
    "\n",
    "    # 3. IPCA (Série 433)\n",
    "    print(\"Baixando IPCA...\")\n",
    "    try:\n",
    "        # IPCA é mensal, então a restrição de 10 anos não se aplica (ou é menos rigorosa)\n",
    "        df_ipca_m = sgs.get({'taxa': 433}, start='2000-01-01')\n",
    "        \n",
    "        # [PERSONALIZAÇÃO] Drop de __id\n",
    "        if \"__id\" in df_ipca_m.columns:\n",
    "            df_ipca_m = df_ipca_m.drop(columns=[\"__id\"])\n",
    "            \n",
    "        # Projeção Diária do IPCA\n",
    "        dr = pd.date_range(df_ipca_m.index.min(), datetime.now(), freq='D')\n",
    "        df_ipca_d = pd.DataFrame({'data': dr}).set_index('data')\n",
    "        df_ipca_d = df_ipca_d.join(df_ipca_m).ffill()\n",
    "        df_ipca_d['valor'] = ((1 + df_ipca_d['taxa']/100)**(1/30)).cumprod()\n",
    "        df_ipca_d['codigo'] = 'IPCADIANI'\n",
    "        df_ipca_final = df_ipca_d.reset_index()[['codigo', 'valor', 'data']]\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no IPCA: {e}\")\n",
    "        df_ipca_final = pd.DataFrame()\n",
    "\n",
    "    # Unificar\n",
    "    df_final = pd.concat([df_m, df_c, df_ipca_final], ignore_index=True)\n",
    "    \n",
    "    # [PERSONALIZAÇÃO] Garantia final contra __id\n",
    "    if \"__id\" in df_final.columns:\n",
    "        df_final = df_final.drop(columns=[\"__id\"])\n",
    "        \n",
    "    df_final['data'] = pd.to_datetime(df_final['data']).dt.date\n",
    "    df_final.columns = [c.lower() for c in df_final.columns]\n",
    "\n",
    "    # Salvar no Banco\n",
    "    connector = db()\n",
    "    with connector.engine.begin() as conn:\n",
    "        conn.execute(text(\"CREATE SCHEMA IF NOT EXISTS middle;\"))\n",
    "        df_final.to_sql('indices_cotas', conn, schema='middle', if_exists='replace', index=False)\n",
    "        conn.execute(text(\"CREATE INDEX IF NOT EXISTS idx_indices_v6 ON middle.indices_cotas (data, codigo);\"))\n",
    "    \n",
    "    print(f\"Sucesso! Índices processados: {df_final['codigo'].unique()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_indices_v6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "053f6ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_cotas = \"\"\"\n",
    "    SELECT \n",
    "        cnpj_fundo, \n",
    "        COALESCE(id_subclasse, 'MASTER') as id_subclasse_clean,\n",
    "        id_subclasse,\n",
    "        dt_comptc, \n",
    "        vl_quota \n",
    "    FROM cvm.fi_doc_inf_diario_inf_diario_fi\n",
    "    WHERE dt_comptc >= '2014-06-01'\n",
    "\"\"\"\n",
    "db = PostgresConnector()\n",
    "df_cotas = db.read_sql(query_cotas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a36f200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cotas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de43dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando cotas (CVM 175 ready)...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sqlalchemy import text\n",
    "from common.postgresql import PostgresConnector\n",
    "\n",
    "def calculate_metrics_175_optimized():\n",
    "    db = PostgresConnector()\n",
    "    \n",
    "    print(\"Carregando cotas (CVM 175 ready)...\")\n",
    "    # Coalesce no id_subclasse para evitar problemas de chave nula no DataFrame\n",
    "    query_cotas = \"\"\"\n",
    "        SELECT \n",
    "            cnpj_fundo, \n",
    "            COALESCE(TEXT(id_subclasse), 'MASTER') as id_subclasse_clean,\n",
    "            dt_comptc, \n",
    "            vl_quota \n",
    "        FROM cvm.cotas \n",
    "        WHERE dt_comptc >= '2014-06-01'\n",
    "    \"\"\"\n",
    "    df_cotas = db.read_sql(query_cotas)\n",
    "    \n",
    "    # [PERSONALIZAÇÃO] Removendo __id conforme instrução\n",
    "    if \"__id\" in df_cotas.columns:\n",
    "        df_cotas = df_cotas.drop(columns=[\"__id\"])\n",
    "\n",
    "    # 1. TRATAMENTO DE DUPLICADOS (Prevenção do ValueError)\n",
    "    # Mantemos apenas o último registro caso haja duplicidade para a mesma data/entidade\n",
    "    print(\"Limpando duplicatas...\")\n",
    "    df_cotas = df_cotas.drop_duplicates(subset=['dt_comptc', 'cnpj_fundo', 'id_subclasse_clean'], keep='last')\n",
    "\n",
    "    # Criar chave única para o pivot\n",
    "    df_cotas['entity_id'] = df_cotas['cnpj_fundo'] + \" | \" + df_cotas['id_subclasse_clean']\n",
    "    \n",
    "    # Carregar Benchmarks\n",
    "    df_bench = db.read_sql(\"SELECT data as dt_comptc, codigo, valor FROM middle.indices_cotas\")\n",
    "    bench_pivot = df_bench.pivot(index='dt_comptc', columns='codigo', values='valor').ffill()\n",
    "    bench_ret = np.log(bench_pivot / bench_pivot.shift(1))\n",
    "\n",
    "    print(\"Pivoteando matriz volumosa...\")\n",
    "    df_cotas['dt_comptc'] = pd.to_datetime(df_cotas['dt_comptc'])\n",
    "    \n",
    "    # Agora o pivot não falhará pois limpamos as duplicatas acima\n",
    "    matrix = df_cotas.pivot(index='dt_comptc', columns='entity_id', values='vl_quota').sort_index().ffill()\n",
    "    \n",
    "    # Retornos logarítmicos matriciais\n",
    "    returns = np.log(matrix / matrix.shift(1))\n",
    "    \n",
    "    # Fechamentos de mês (último dia útil)\n",
    "    fechamentos = df_cotas['dt_comptc'].groupby([df_cotas['dt_comptc'].dt.year, df_cotas['dt_comptc'].dt.month]).max()\n",
    "    fechamentos = fechamentos[(fechamentos >= '2015-01-01') & (fechamentos <= '2025-12-31')]\n",
    "\n",
    "    janelas = {'6M': 126, '12M': 252, '24M': 504, '36M': 756, '48M': 1008, '60M': 1260}\n",
    "    final_results = []\n",
    "\n",
    "    # Cache de idade (primeira cota de cada entidade)\n",
    "    primeira_cota = matrix.apply(lambda x: x.first_valid_index())\n",
    "\n",
    "    for dt_ref in fechamentos:\n",
    "        print(f\"Calculando {dt_ref.date()}...\")\n",
    "        idx_fim = matrix.index.get_indexer([dt_ref], method='pad')[0]\n",
    "        \n",
    "        for label, dias in janelas.items():\n",
    "            idx_ini = max(0, idx_fim - dias)\n",
    "            if idx_fim <= idx_ini: continue\n",
    "            \n",
    "            window_ret = returns.iloc[idx_ini+1 : idx_fim+1]\n",
    "            if window_ret.empty: continue\n",
    "\n",
    "            # --- VETORIZAÇÃO ---\n",
    "            cum_ret = np.exp(window_ret.sum()) - 1\n",
    "            vol = window_ret.std() * np.sqrt(252)\n",
    "            \n",
    "            # Drawdown e MDD\n",
    "            cum_prices = np.exp(window_ret.cumsum())\n",
    "            running_max = cum_prices.cummax()\n",
    "            mdd = ((cum_prices / running_max) - 1).min()\n",
    "            \n",
    "            # Sharpe (RF = CDINI)\n",
    "            rf_total = np.exp(bench_ret['CDINI'].iloc[idx_ini+1 : idx_fim+1].sum()) - 1\n",
    "            # Evita divisão por zero na volatilidade\n",
    "            vol_safe = vol.replace(0, np.nan)\n",
    "            sharpe = (cum_ret - rf_total) / vol_safe\n",
    "            \n",
    "            # Calmar e Sortino\n",
    "            calmar = cum_ret / abs(mdd).replace(0, np.nan)\n",
    "            downside_std = window_ret[window_ret < 0].std() * np.sqrt(252)\n",
    "            sortino = (cum_ret - rf_total) / downside_std.replace(0, np.nan)\n",
    "            \n",
    "            # Expected Shortfall (5%)\n",
    "            es = window_ret.quantile(0.05)\n",
    "\n",
    "            # Idade e Filtro de Existência\n",
    "            idade_real_meses = ((dt_ref - primeira_cota).dt.days / 30.44).round(2)\n",
    "            \n",
    "            batch = pd.DataFrame({\n",
    "                'entity_id': matrix.columns,\n",
    "                'dt_comptc': dt_ref.date(),\n",
    "                'janela': label,\n",
    "                'ret': cum_ret,\n",
    "                'vol': vol,\n",
    "                'mdd': mdd,\n",
    "                'sharpe': sharpe,\n",
    "                'sortino': sortino,\n",
    "                'calmar': calmar,\n",
    "                'es': es,\n",
    "                'hit_ratio': (window_ret > 0).sum() / len(window_ret),\n",
    "                'meses_observados': np.minimum(idade_real_meses, dias/21)\n",
    "            }).dropna(subset=['ret'])\n",
    "\n",
    "            batch = batch[batch['entity_id'].map(primeira_cota) <= dt_ref]\n",
    "            \n",
    "            # Reverter entity_id para colunas separadas\n",
    "            split_cols = batch['entity_id'].str.split(\" | \", expand=True, n=1)\n",
    "            batch['cnpj_fundo'] = split_cols[0]\n",
    "            batch['id_subclasse'] = split_cols[1].replace('MASTER', np.nan)\n",
    "            \n",
    "            final_results.append(batch.drop(columns=['entity_id']))\n",
    "\n",
    "    # Consolidação e Information Ratio\n",
    "    df_final = pd.concat(final_results, ignore_index=True)\n",
    "    \n",
    "    # [INFO RATIO]\n",
    "    df_classes = db.read_sql(\"SELECT cnpj_fundo, classe FROM cvm.fi_cad_fi_hist_classe\")\n",
    "    # [PERSONALIZAÇÃO] Drop __id da tabela de classe\n",
    "    if \"__id\" in df_classes.columns: df_classes = df_classes.drop(columns=[\"__id\"])\n",
    "    \n",
    "    df_final = df_final.merge(df_classes.drop_duplicates('cnpj_fundo'), on='cnpj_fundo', how='left')\n",
    "    \n",
    "    # Benchmarks para IR\n",
    "    ret_ibov = np.exp(bench_ret['IBOV'].sum())-1\n",
    "    ir_ibov = (df_final['ret'] - ret_ibov) / df_final['vol'].replace(0, np.nan)\n",
    "    ir_cdi = (df_final['ret'] - rf_total) / df_final['vol'].replace(0, np.nan)\n",
    "    \n",
    "    df_final['info_ratio'] = np.where(df_final['classe'].str.contains('Ações', na=False), ir_ibov, ir_cdi)\n",
    "\n",
    "    print(f\"Salvando {len(df_final)} linhas...\")\n",
    "    with db.engine.begin() as conn:\n",
    "        conn.execute(text(\"CREATE SCHEMA IF NOT EXISTS middle;\"))\n",
    "        df_final.to_sql('fundos_metricas_175', conn, schema='middle', if_exists='replace', index=False)\n",
    "        conn.execute(text(\"\"\"\n",
    "            CREATE INDEX IF NOT EXISTS idx_metricas_175 \n",
    "            ON middle.fundos_metricas_175 (cnpj_fundo, id_subclasse, dt_comptc, janela);\n",
    "        \"\"\"))\n",
    "\n",
    "    print(\"Processo concluído com sucesso!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    calculate_metrics_175_optimized()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
